{
	"projects": [{
			"name": "Fashion App",
			"subdomain": "community_fashion",
			"category": ["UX design", "networked", "participatory", "mobile", "lead", "methods"],
			"subtitle": "Designing a Community-Centered Fashion Discovery Platform",
			"collaborators": ["Jaden Castle", "Jessica Vo"],
			"abstract": "A participatory design project focused on creating a mobile app for showcasing outfits, tagging items with prices, and fostering community engagement through interactive features. The app combines intuitive discovery tools with customizable user profiles to balance self-expression and inspiration.",
			"description": ["This project aimed to address the need for a community-focused fashion platform by implementing a blend of discovery and self-expression features. Research methods like surveys, user personas, and competitor analysis guided the design process, ensuring the app met user needs and filled market gaps."],
			"mainimg": "tapart.jpg",
			"video": ["False"],
			"images": ["tapart.jpg", "mario and luigi cropped.PNG", "draw 1.PNG", "dance actually.PNG", "robot marbles.PNG"]
			
	},{"name": "Women in CS First Year Project",
			"subdomain": "inclusion_in_tech",
			"category": ["research", "equity", "education", "participatory", "qualitative methods"],
			"subtitle": "Exploring First-Year Experiences of Women in Computer Science",
			"collaborators": ["Lecia Barker (Lead)", "Noah Cowit","Jaden Castle", "Mayce Miller"],
			"abstract": "A study investigating the experiences of first-year women in computer science majors, focusing on inclusionary and exclusionary behaviors, identity formation, and sense of belonging. The research aims to shed light on how classroom, peer, and departmental dynamics affect retention and inclusivity in the CS field.",
			"description": ["This project addresses the ongoing challenge of fostering inclusivity in computer science education by examining first-year women’s experiences. The study explores factors contributing to retention and attrition, particularly in the absence of faculty, such as in peer interactions and informal group settings.",
        	"Data collection involves near-peer interviews conducted by undergraduate researchers. These interviews focus on capturing micro-affirmations, micro-aggressions, and other inclusionary or exclusionary experiences encountered in classrooms, labs, and extracurricular environments. To contextualize findings, the research team also considers institutional data, such as enrollment growth, department resources, and teaching approaches."],
			"mainimg": "/portfolio/imgs/wics.jpeg",
			"video": ["False"],
			"images": ["tbots_cover.png"],
			"citations": [["National Center for Women & Information Technology (NCWIT). 2024. <span>Retention Strategies for Women in Computing</span>. Internal Research Documentation."]]

	},{
			"name": "Designing Sensory Extensions for Interactive Simulations",
			"subdomain": "ratio_and_proportion",
			"category": ["tangible", "participatory", "educational", "publication", "lead", "education"],
			"subtitle": "Investigating Sensory Extensions as Input for an Interactive Math Simulation",
			"collaborators": ["Chris Hill (Co-Lead)", "Sammie Crowder", "Brett Fielder", "Emily Moore", "Ann Eisenberg"],
			"abstract": "Sensory extensions transduce stimuli to extend awareness. Our suite of wearable devices extend learner's perceptions of the math concept of ratios and proportions by facilitating embodied interactions with an associated simulation (GUI).",
			"description": ["Sensory extensions enhance our awareness by transforming variations in stimuli normally undetectable by human senses into perceivable outputs. Similarly, interactive simulations for learning promote an understanding of abstract phenomena. Combining sensory extension devices with interactive simulations gives users the novel opportunity to connect their sensory experiences in the physical world to computer-simulated concepts. We explore this opportunity by designing a suite of wearable sensory extension devices that interface with a uniquely inclusive PhET Simulation, Ratio and Proportion. In this simulation, two hands can be moved on-screen to various values, representing different mathematical ratios. Users explore changing hand heights to find and maintain ratios through visual and auditory feedback. Our sensory extension devices translate force, distance, sound frequency, and magnetic field strength to quantitative values in order to control individual hands in the computer simulation. This paper describes the design of the devices and our analysis of feedback from 23 high-school aged youth who used our designs to interact with the Ratio and Proportion."],
			"mainimg": "sensoryextension_cover.jpg",
			"video": ["True","True"],
			"images": ["sensoryextension_cover.jpg", "sensory_extension_render.png", "using_se.jpg"],
			"video_id": "naIZ2wla7WA",
			"published": ["True","1"],
			"citations": [["Chris Hill, Casey Lee Hunt, Sammie Crowder, Brett Fiedler, Emily B. Moore, and Ann Eisenberg. 2023. <span>Investigating Sensory Extensions as Input for Interactive Simulations</span>. In Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '23). Association for Computing Machinery, New York, NY, USA, Article 39, 1–7.", "https://caseyhunt.github.io/assets/tei-23.pdf", "View on ACM", "https://dl-acm-org.colorado.idm.oclc.org/doi/abs/10.1145/3569009.3573108"]]

		},{
			"name": "Cyber Garden",
			"subdomain": "cyber_garden",
			"category": ["tangible", "participatory", "lead"],
			"subtitle": "Ambient Community Wellness Display ",
			"collaborators": ["Ruojia Sun", "Kit Lewers", "Sandra Bae", "Steve Voida"],
			"abstract": "An ambient display that invites students and faculty to share and reflect on their stress as a community. With a combination of self-reported and biometric data, the community controls each robotic flower in the bouquet to record stress via closed or blooming buds.",
			"description": ["We are inspired by related work in ambient displays as a promising technology for community wellness interfaces. Ambient displays are particularly applicable to community wellness, since they are well-suited for enabling continuous, background awareness of general states of large systems. There have been several works which use ambient displays to support mental wellness and stress management. For example, MoodLight is an interactive ambient lighting system that responds to epidermal activity biosensor data related to the user’s stress level. ", "With Cyber Garden, we design an ambient display for graduate students to report personal stress through biometrics and self-reported data. We use this data to create an anonymized, interactive visualization. We leverage previous workshops conducted with graduate students to ground our approach. When asked about burnout, these graduate students shared a desire to reach out for help, but reported not having a clear mechanism to do so. Additionally, these students reported that they would feel less alone in their difficult emotions if there was a way to see the challenging states of others."],
			"mainimg": "cgarden.jpeg",
			"video": ["False"],
			"images": ["cgarden.jpeg", "garden_display.jpeg", "garden_full.jpeg"]
		},
		

		{
			"name": "Presence Mat",
			"subdomain": "presence_mat",
			"category": ["tangible", "award", "lead"],
			"subtitle": "Low-Cost Room-Scale Radar for the Home with Off-The-Shelf Hardware",
			"collaborators": ["Daniel Leithinger"],
			"abstract": "A system built with off-the-shelf Ultra-High frequency RFID to create a room-scale radar system. Using deep learning Presence Mat approximates body position for yoga-based interaction.",
			"description": ["As virtual assistants and remote classes become increasingly common in fitness, so too does the need to reliably recognize human posture and activity. We build a system that explores how device-free Ultra-High Frequency Radio Frequency Identification (UHF RFID) enables low-cost fitness tracking without the trade-offs of worn sensors or cameras.", "Because UHF RFID systems are subject to signal shielding by the human body, it is possible to utilize returned signal strength from passive tags to infer user position. However, because previous implementations only support low resolution activity recognition, application of this technology to fitness tracking is limited. With deep learning and a constrained the sensing area, we demonstrate increased fidelity, in spite of our focus on off-the-shelf systems (which provide fewer readings per second)."],
				"mainimg": "mat.jpg",
				"video": ["False"],
				"images": ["mat.jpg"]
			},

			


			{
				"name": "DOT",
				"subdomain": "dot",
				"category": ["tangible", "toolkit", "lead"],
				"subtitle": "Device for Object Based Telepresence",
				"collaborators": ["Ruhan Yang", "Daniel Leithinger"],
				"abstract": "A platform that utilizes tabletop swarm robots to create a dynamic tangible display. The system recognizes the identity of objects placed on the surface, and a paired display reacts to this configuration. Created for the 2021 UIST Student Innovation Challenge.",
				"description": ["DOT, is a tabletop tangible display that detects and integrates everyday objects. Using swarm robots, we create a scalable, portable tangible interface. Two toio robots are combined with an assembly that contains a magnet with a lift screw, allowing the system to move magnet-containing objects placed on the tabletop. The resulting platform can be used for tangible play, communication, and co-creation.", "In contrast to previous approaches that use computer vision and fixed cameras for object recognition combined with a modified table, the toios in DOT recognize objects using markers placed on the base of the object, then move them. Because DOT uses a palm-sized assembly for both object recognition and movement, it does not require a stationary setup for object recognition."],
				"mainimg": "dot.jpg",
				"video": ["False"],
				"images": ["dot.jpg"]
			},

			{
				"name": "VTTV",
				"subdomain": "vttv",
				"category": ["tangible", "toolkit", "award", "support", "tangible"],
				"subtitle": "Vibrotactile Tongue Display",
				"collaborators": ["Mary Etta West (Lead)", "Netta Ofer", "Sandra Bae", "Chris Hill"],
				"abstract": "VTTV is a seven segment vibrotactile display that combines taste and vibration to create haptic art for the tongue. The system provides a unique platform for crafting playful, flavorful, vibrotactile experiences. This project recieved honorable mention in the Student Design Competition at World Haptics Conference 2020.",
				"description": ["The Vibrotactile Tongue Vision (VTTV) system is an open-source programmable tongue display unit (TDU) that augments visual and auditory experiences through haptic feedback. VTTV is designed to enable those without embedded systems skills to fabricate a TDU, controller, and craft tactile experiences easily. The project also includes a controller to program haptic patterns directly to the VTTV system.", "TDUs typically use electrotactile stimulation to display information to the user. These systems produce sensations by generating voltage pulses from electrodes to the user’s tongue. Commercial TDU systems are closed source, prohibitively expensive, and compromise haptic resolution for user comfort. We propose an alternative to electrotactile TDUs, a novel system that uses ERM motors for actuation. Our goal is to enable anyone to fabricate their own TDU using easily accessible materials with affordable off-the-shelf tools."],
				"mainimg": "vttv.jpeg",
				"video":["True", "True"],
				"images": ["vttv.jpeg", "TDU.PNG", "vttv_unsealed.jpg", "vttv_sealed.jpeg", "vttv_candy.jpeg", "vttv_chris.jpeg"],
				"video_id": "UD9IrikeVV8"
			},

			{
				"name": "Everything Instrument",
				"subdomain": "everything_instrument",
				"category": ["tangible", "toolkit", "support", "education"],
				"subtitle": "Turn Anything Into an Instrument",
				"collaborators": ["Ruhan Yang (Lead)"],
				"abstract": "A platform that allows people to turn anything into an instrument using copper tape. After applying copper tape to everyday household objects, users attach their creation to Everything Instrument, using buttons to customize the pitch and character of their sound. Designed for the SynthUX 2021 hackathon.",
				"description": ["Using capacitive touch, PaperMagnets, a few buttons, and a microphone, we create amodular system that allows any object to become a part of the orchestra. We demonstrate this platform by building a melodica, keyboard, cello, trombone, and percussion. The system utilizes the capacitive touch breakout to create a 12 tone scale. From there, we utilize up to six buttons to modify the sound. In the case of the melodica and keyboard, the buttons can be used to change octaves. In the case of the cello, the buttons function as strings. The wind instruments utilize a microphone in the mouthpiece to detect whether and how hard air is being blown into the instrument."],
				"mainimg": "ei.jpeg",
				"video": ["True", "True"],
				"images": ["ei.jpeg"],
				"video_id":"DRxS6wDXom8"
			}
		]



	}